---
title: IQSR Analyzing Survey Data (Part II)
author:
  - Chao-Yo Cheng
output:
  beamer_presentation:
    includes:
      in_header: mystyle.tex
  slidy_presentation: default
fontsize: 10pt
---

## Plan ahead

\begin{itemize}
  \item Weeks 4 and 5: Analyzing survey data
  \begin{itemize}
    \item Week 4: Survey design and descriptive analysis of survey data.
    \item \textbf{Week 5: Inferential (regression) analysis of survey data}.
  \end{itemize}
  \item Weeks 8 and 9: Multilevel models
  \item Week 10: Review for exams
\end{itemize}

## Outline for today

\begin{itemize}
  \item Week 5 takeway: \textbf{\textit{"To use weights or not, that is the question"}}
  \item Regression analysis of survey data
  \item Revisiting logistic (logit) regression -- how we get from OLS to GLM
  \item Live session: Studying the correlates of public views towards abortion
\end{itemize}

## Week 5 lecture takeway

\begin{itemize}
  \item Survey is one of the most common social research techniques; researchers seek to draw useful information about the \textbf{population} based on a \textbf{sample}.
  \item A survey needs to be carefully designed to ensure sure the "sample" is \textbf{representative} of the population. \textbf{Simple random sampling} is a common sampling approach.
  \item We use \textbf{survey weights} to correct or adjust the unrepresentative sample so the results can speak to the  population.
  \item Without weights, our findings can be \textbf{biased} (due to the unrepresentative sample) or can only apply to a unique subset of population (i.e., \textbf{not generalizable}).
\end{itemize}

## Week 5 live session recap

\begin{itemize}
  \item In \texttt{R}, we use functions provided by packages "\texttt{survey}" and "\texttt{srvyr}" so as to include weights in our analysis.
  \begin{small}
  \begin{itemize}
    \item First, turn the data frame into a \textbf{survey} object.
    \item Next, use the summary statistics functions (e.g., \texttt{survey\_total()}) in both packages to carry out descriptive and inferential analysis.
  \end{itemize}
  \end{small}
  \vspace{0.1cm}
  \item Check out the package manuals and vignettes:
  \begin{small}
  \begin{itemize}
    \item \texttt{survey}: \url{https://r-survey.r-forge.r-project.org/survey/}.
    \item \texttt{srvyr}: \url{http://gdfe.co/srvyr/index.html}.
  \end{itemize}
  \vspace{0.1cm}
  \end{small}
  \item The UCLA handout (link on Moodle) has a work example for the use of \texttt{survey} package.
\end{itemize}

## Regression analysis of survey data

\begin{itemize}
  \item Varieties of model choices -- depending on the response variables.
  \pause
  \begin{itemize}
    \item Continuous variable: OLS
    \item Binary variable: Logit/probit
    \item Ordinal variable: Ordered logit/probit
    \item Categorical variable: Multinomial logit/probit
  \end{itemize}
  \pause
  \item Resources:
  \begin{itemize}
    \item "R Data Analysis Examples" by UCLA Statistical Methods and Data Analytics (\url{https://stats.oarc.ucla.edu/other/dae/}). -- you can find many practical examples here.
    \item "Regression and Other Stories" (2020) by Aki Vehtari, Andrew Gelman, and Jennifer Hill. -- if you need a comprehensive coverage.
  \end{itemize}
\end{itemize}

## Regression analysis of survey data

\vspace{0.1cm}
\begin{figure}
  \centering
  \includegraphics[scale=0.55]{Figs/box}
\end{figure}
\begin{center}
"All models are wrong;" be an informed quantitative researcher.
\end{center}

## Logit regression revisited

\begin{itemize}
  \item Steps for today's review (when you read through the slides, feel free to start from anywhere):
  \begin{itemize}
    \item Step 1: OLS recap (3 slides).
    \item Step 2: From OLS to GLMs (1 slide).
    \item Step 3: Logit as the workhorse GLM (6 slides).
  \end{itemize}
  \vspace{0.2cm}
  \item Not covered here: Model assumptions, diagnostics, and comparison (they will be discussed in the review workshop).
\end{itemize}

## Step 1: OLS recap

\begin{small}
\begin{itemize}
  \item "Linear regression" (or \textbf{ordinary least squares}, aka OLS) means we use a \textbf{linear} (i.e., straight line) function to model the relationship between $X$ (predictors) and $Y$ (dependent variable).
  \vspace{0.2cm}
  \item A simple \textbf{bivariate} (i.e., two-variable or one $X$) OLS can be specified as a linear function $$Y=\alpha+\beta X+\epsilon,$$ where $\alpha$ and $\beta$ are the \textbf{intercept} (or constant) and the \textbf{slope} (or the regression coefficient) of the linear function.
  \vspace{0.2cm}
  \item OLS aims to find the \textbf{"best"} fit of the regression line based on our data.
  \begin{small}
  \begin{itemize}
    \item In plain English, the estimated $\hat{\alpha}$ and $\hat{\beta}$ will be a line that produced the smallest residuals/errors.
    \item Formally speaking, the estimated regression line will produce the smallest \textbf{sum of squared errors} or \textbf{sum of squared residuals} (this is where the name of OLS came from).
  \end{itemize}
  \end{small}
\end{itemize}
\end{small}

## Step 1: OLS recap

\begin{figure}
  \centering
  \includegraphics[scale=0.72]{Figs/ols}
\end{figure}

## Step 1: OLS recap

\begin{small}
Consider the following linear regression model: $$\text{Vote}=50+2\times\text{Hours}.$$ The model shows the relationship between \textbf{Hours} (the number of hours a party spends on campaigning during the election) and \textbf{Vote} (the percentage of votes won by the party).
\begin{itemize}
  \item We can (attempt to) use this model to predict a party's vote share. For instance, when Hours$=0$, Vote=$50$; when Hours$=1$, Vote=$52$.
  \item A party will get 50\% of votes without doing any campaigning at all.
  \item A party can increase its vote share 2 percentage points (i.e., from 50\% to 52\% of votes) if they spend one additional hour campaigning.
\end{itemize}
\end{small}

## Step 2: From OLS to GLM

\begin{small}
\begin{itemize}
  \item \textbf{OLS will produce weird predictions} when $Y$ is binary (i.e., each observation can only take one of the two values, say either 0 or 1) or bounded. 
    \begin{itemize}
      \item Using the same example, Vote$=110$ with Hours$=30$; no party can get 110\% of the votes.
      \item From the probability perspective, OLS may generate predictions larger than 1 and lower than 0 (and these predictions make no sense in real life).
    \end{itemize}
  \vspace{0.1cm}  
  \item \textbf{Key OLS assumptions can be violated} when $Y$ is binary, such as
    \begin{itemize}
      \item \textbf{Normality}: OLS may create errors that are not normally distributed.
      \item \textbf{Homoscedasticity}: OLS may create predictable errors (using $X$) rather than just random noise.
    \end{itemize}
  \pause
  \vspace{0.1cm}
  \item Further ref: Long, J. Scott. 1997. \textit{Regression Models for Categorical and Limited Dependent Variables}. Los Angeles, CA: Sage -- see pp. 38-40.
  %\item Breen, Richard, et al. 2018. "Interpreting and Understanding Logits, Probits, and Other Nonlinear Probability Models." \textit{Annual Review of Sociology 44}: 39-54.
\end{itemize}
\end{small}

## Step 3: Logit regression

\begin{itemize}
  \item Logit regression is used to model a \textbf{binary} outcome or a probability, which we denote as $p$. By definition,
  \begin{itemize}
    \item A probability $p$ can only take the values between 0 and 1 (e.g., whether or not two countries fight each other) such that $p=1$ means an event takes place.
    \item The probability of something happening (e.g., two countries fight) and that of some not happening (e.g., two countries do not fight) will sum up to 1.
  \end{itemize}
  \vspace{0.2cm}
  \item Logit regression is a \textbf{generalized linear model} (GLM), meaning that we are using a \textbf{linear function} to model a \textbf{non-linear relationship} between $X$ and $Y$ (see an example on the next slide).
\end{itemize}

## Step 3: Logit regression

\begin{figure}
  \centering
  \includegraphics[scale=0.5]{Figs/logit}
\end{figure}
\vspace{0.1cm}
\begin{center}
The correlation between gross horsepower and whether or not a car has straight engine, using logit regression. Each blue dot is an observation in the dataset.
\end{center}

## Step 3: Logit regression

\begin{small}
\begin{itemize}
  \item Logit regression uses the \textbf{logit} link function, which transform $p$ (probability) into $\log\left(\frac{p}{1-p}\right)$ (the log-odds): $$\text{logit}(p)=\log\left(\frac{p}{1-p}\right).$$
  \vspace{0.3cm}
  \item A simple bivariate logit regression can be specified as follows: $$\log\left(\frac{p}{1-p}\right)=\alpha+\beta X+\epsilon.$$
  \vspace{0.3cm}
  \item \textbf{Let's unpack the bivariate logit regression step by step.} We will start with the left hand side before moving on to the right hand side. 
\end{itemize}
\end{small}

## Step 3: Logit regression

$$\log\left(\frac{p}{1-p}\right)=\alpha+\beta X.$$
\begin{small}
\begin{itemize}
  \item If $p$ is the probability of an event, then the odds is $\frac{p}{1-p}$, which suggests the chance of an event taking place relative to the opposite scenario.
  \begin{itemize}
    \item Say today's probability of raining is 0.8, $p=0.8$ (the \textbf{probability} of raining) and $1-p=0.2$ (the probability of not raining).
    \item Next, the \textbf{odds} of raining is then $\frac{p}{1-p}=\frac{0.8}{1-0.2}=4$.
    \item Finally, the \textbf{log of odds} here is thus $\log\left(\frac{p}{1-p}\right)=\log(4)$ or the log of 4 with $e$ (a mathematical constant) as the base.
  \end{itemize}
  \item \textbf{Logit link function allows us to transform $p$, the original dependent variable, into log-odds such that the dependent variable is no longer bounded between 0 and 1}; it can also go negative.
\end{itemize}
\end{small}

## Step 3: Logit regression

$$\log\left(\frac{p}{1-p}\right)=\alpha+\beta X\quad\text{a.k.a}\quad\log\left(\text{Odds}\right)=\alpha+\beta X$$ \
\vspace{0.2cm}
\begin{small}
\textbf{One-unit increase in $X$} (e.g., moving $X$ from 0 to 1) corresponds to
\begin{itemize}
    \item $\beta$ changes in $\log\left(\frac{p}{1-p}\right)$, or the \textbf{log odds}, such that
    \begin{equation}
    \begin{split}
    \beta&=\log(\text{Odds When X=1})-\log(\text{Odds When X=0})\\
    &=\log\left(\frac{\text{Odds When X=1}}{\text{Odds When X=0}}\right).
    \end{split}
    \end{equation}
    \item The exponent of $\beta$ will return the {odds-ratio} (OR), or $$e^{\beta}=\frac{\text{Odds When X=1}}{\text{Odds When X=0}}.$$ Intuitively, it measures how the odds change when we move $X$ from 0 to 1.
    %\item $\frac{\hat{\beta}}{4}$ as \textbf{the upper bound of changes in $p$} (see "divide-by-four" principle, Gelman and Hill 2007, p.82);
    \vspace{0.3cm}
\end{itemize}
\end{small}

## Step 3: Logit regression

Consider the following logit regression model:\
\vspace{0.1cm}
$$\text{logit}(\text{Win})=\log\left(\frac{\text{Win}}{1-\text{Win}}\right)=-1.40+0.33\times\text{Hours}.$$\
\vspace{0.2cm}
This model shows the relationship between \textbf{Hours} (the number of hours a party spends on campaign during the election) and \textbf{Win} (the probability of winning the election).
\begin{small}
\begin{itemize}
  \item When the party spends one additional hour on campaigns, we know
  \begin{itemize}
    \item the corresponding change in log-odds of winning is $0.33$.
    \item the corresponding odds-ratio is $e^{0.33}\approx 1.39$.
    %\item the largest possible change in $p$, the probability of winning, is $\frac{0.33}{4}=0.0825$.
  \end{itemize}
  \item Should the party spend more time on campaigns?
\end{itemize}
\end{small}

---

$$e^{\beta}=\frac{\text{Odds When X=1}}{\text{Odds When X=0}}.$$\
\vspace{0.3cm}
\begin{figure}
  \centering
  \includegraphics[scale=0.6]{Figs/or_table}
\end{figure}
\begin{center}
Given that $\text{OR}_{Hours}>1$, the data support more hours on campaigns.
\end{center}

## Live session teaser

\begin{itemize}
  \item Draw on the 2011 Canadian National Election Study.
  \item Use packages \texttt{survey} or \texttt{srvyr} to create a survey object in \texttt{R} based on the survey design (e.g., strata and weights) -- we have done this in Week 4.
  \item Use logit, such as \texttt{glm()} and \texttt{svyglm()} in \texttt{survey} package, to study the correlates of public attitudes against abortion.
  \item Use the \texttt{predict()} function in \texttt{R} to obtain predicted log-odds and probabilities.
\end{itemize}
