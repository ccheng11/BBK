---
title: "Tutorial 2: Logit Regression"
author: ""
abstract: ""
date: today
date-format: long
fontsize: 11pt
papersize: lettersize
indent: false
linestretch: "1.1"
format:
  pdf:
    keep-tex: false
    fig_caption: yes
    number-sections: true
    shift-heading-level-by: 0
    reference-links: true
    reference-location: document
    toc: false
    pdf-engine: "xelatex"
---

In this problem set, we will first review the main concepts of logarithms and probability. Next, we will then use logit regression to analyze the replication data of a recently published article. The key objectives are to help you understand carry out logit regression in `R` and interpret the results using odds ratio and predicted probability.

Before you start, please download the dataset from Moodle and import it into `RStudio`. If you would like to submit this problem set, please complete the questions at the end.

# A Recap on Logarithm

A **logarithm** is the opposite of a **power**. In other words, if we take a logarithm of a number, we undo an exponentiation. To put it simply

  - We raise **base** to a specified **power** to derive the result of an **exponentiation**.
  - Logarithm means we use the result of an **exponentiation** and a given **base** to derive the corresponding **power**.

We can start with simple example. If we take the base $b=2$ and raise it to the power of $k=3$, we can express this procedure as $2^3$. We can carry out the calculation easily in `R` as follows.

Suppose we call the result as $c$ as follows $2^3=c$. We can use the rules of exponentiation to calculate that the result is $$c=2^3=8.$$

```{r, echo=T, eval=T, message=F}
c <- 2^3
c
```

Now, say we do now know the value of $k$; instead, we know that the base is $b=2$ and the final result of the exponentiation is $c=8$ such that $2^k=8$.

From the above calculation, we already know that $k=3$. But, what if now the result of the exponentiation was $c=4$, so we need to solve $2^k=4$?

A logarithm is a function that does all this work for us. We define a logarithm with the base 2 to be the solution to the problems above. Log with a base of 2 is defined so that $$\log_2c=k,$$ where $k$ refers to the power and $c$ refers to the result of exponentiation when we raise 2 to the power of $k$.

For the purpose of logit regression, we will use a special type of logarithm with base $e$: $$\log_ec=k,$$ which sometimes can be written as $$\ln c=k.$$ To obtain $c$, the results of rasing $e$ to the power of $k$, we will need to take the exponent of $k$ as follows $$e^k=c.$$ In `R`, we have functions such as `log()` and `exp()` to take the log and exponent with base $e$. 

```{r, echo=T, eval=T, message=F}
log(4, base=2) # log of 4 with base 2
log(4) # log of 4 with base e
?log # see what log() does
```

To derive odds ratio, we will need the *quotient* rule: $$\log\left(\frac{a}{b}\right)=\log a-\log b.$$

\newpage

# Variables

We will study the replication data of the following paper: 

**Besley, Celeste, and Scott Cooper. 2022. "Micro-Foundations of the Commercial Peace: The Effect of Net Exports on Ukrainian Attitudes towards War with Russia." *Journal of Peace Research*. Online first.**    

The *Journal of Peace Research* is an interdisciplinary and international peer-reviewed journal, published and owned by the **Peace Research Institute Oslo** (PRIO).

PRIO requires all authors to provide the statistical programming script and data so readers can replicate the findings in the papers. You can find replication packages for all the papers here: \url{https://www.prio.org/journals/jpr/replicationdata}.

Part of the data used in this article was retrieved from the **Global Attitudes Survey** (April 2015) conducted by the **Pew Research Center** based in Washington DC. The **Global Indicators Database** is highly recommended: \url{https://www.pewresearch.org/global/database/}.

This project surveyed 2,071 respondents from 23 provinces. No surveys in Donetsk or Luhansk for security reasons. We will consider some of the following predictors that can help explain the attitudes of Ukrainian attitudes towards the territorial integrity of the country.

  - `secede` -- a binary variable for respondents saying "yes" to the following question: "*In your opinion, should Ukraine remain one, united country or should regions that want to leave be allowed to secede?*"

  - `above3Khryv` -- a binary variable for respondents living in a household with monthly income above 3,000 hryvnia

  - `age` -- a continuous variable to indicate the age of individual respondents based on the following question: *How old were you at your last birthday?*

  - `female` -- a binary variable for respondents who were identified as female

  - `ukrspeakhome` -- a binary variable for respondents who speak Ukranian at home

  - `Russiathreat` -- an ordinal variable for considering Russia as a threat to Ukraine; 3-point scale: major threat ($=3$), minor threat ($=2$), not a threat ($=1)

Let's read in the data and check that all of our variables are as described. 

```{r, echo=T, eval=T, message=F}
library(haven)
library(tidyverse)
library(stargazer)
```

We will use `read_dta` this time because the original dataset `Pew data JPR.dta` is in the `.dta` format for Stata.

```{r, echo=F, eval=T, message=F}
setwd("C:/Users/polar/Downloads/Sandbox/Teaching/AdvQ/Week 03/02 Exercise/Data")
dta <- haven::read_dta("Pew data JPR.dta")
```

```{r, echo=T, eval=F, message=F}
dta <- read_dta("Pew data JPR.dta")
```

We will also carry out a similar process to select the variables we need.

```{r, echo=T, eval=T, message=F}
dta_sel <- dta |>
  dplyr::select(secede, above3Khryv, age, female, ukrspeakhome, Russiathreat)
```

We can use `summary()` to get a snapshot of the summary statistics of each variable.

```{r, echo=T, eval=T, message=F}
summary(dta_sel)
```

# Logit Regression

Our task it to use function `glm()` and estimate the correlates of *people's support for secession*.

  - First, we will fit the logit model with no predictor and use the estimated intercept to uncover the estimated probability of respondents supporting secession.

  - Next, we will fit the logit model with one predictor and interpret the estimated slope using odds-ratio and (if possible) predicted probability using `predict()`.

## Fit Logit Regression With Intercept Only

We will start with a simple model with no predictor. This exercise will help you become familiar with the differences between **probability**, **odds** and **log odds**.

Quickly recall the logit link function transforms a **probability** into **log odds**: $$\text{logit}(p)=\log\left(\frac{p}{1-p}\right),$$ where $p$ is the **probability** of respondents supporting succession.

If we only include the intercept in the model (i.e., no predictor), then our model is as follows: $$\log\left(\frac{p}{1-p}\right)=\alpha+\epsilon.$$ The estimated intercept will be the estimated *log odds* of people supporting secession.

Let's go ahead and fit the model. Use the `summary()` function to see the output. 

```{r, echo=T, eval=T}
mod_intercept <- glm(secede ~ 1,
                     data = dta_sel,
                     family = binomial)
summary(mod_intercept)
```

Looking at the output, we know $\widehat{\alpha}=-1.88891.$ Let's use `coef()` to extract the coefficient.
  
```{r, echo=T, eval=T}
coefs <- coef(mod_intercept) # extracting log odds
coefs
```  
  
Next, we can take the exponent of the log odds to get the *odds* of people against abortion (i.e., use `exp()`). **Rule of thumb: use `exp()` to turn log odds into odds.**
  
```{r, echo=T, eval=T}
exp(coefs) # calculating odds
```

Third, we can compute the *probability* of people against abortion. From the previous step, since the odds is $\frac{p}{1-p}=0.1511005$, we know $p=\frac{0.1511005}{1+0.1511005}=0.1312661$.

```{r, echo=T, eval=T}
exp(coefs)/(1+exp(coefs)) # calculating p
```

We can show the **confidence interval** of the estimated log odds, using the `confint()` function. These are the upper and lower bounds of the 95\% confidence intervals.

```{r, echo=T, eval=T, message=F}
coefs_ci <- confint(mod_intercept)
coefs_ci
```

We can also use the upper and lower bounds of log odds to calculate the upper and lower bounds of estimated odds and probabilities.*

```{r, echo=T, eval=T, message=F}
coefs_ci <- confint(mod_intercept)
coefs_ci # CIs of log odds
exp(coefs_ci) # CIs of odds
exp(coefs_ci)/(1+exp(coefs_ci)) # CIs of probability
```

We can verify the estimated $p$, or the estimated probability of respondents supporting secession by taking the mean of the dependent variable.

```{r, echo=T, eval=T, message=F}
mean(dta_sel$secede, na.rm=T)
```

### Summary

To sum up the whole process again, when we only include the intercept in the logit regression model:

  - $\log\left(\frac{p}{1-p}\right)=\alpha;$ the estimated intercept is the estimated **log odds**,

  - $e^\alpha=\frac{p}{1-p}$ the exponent of the estimated intercept is the estimated **odds**, and

  - once we solve the equation for $p$ it follows that $p=\frac{e^\alpha}{1+e^\alpha},$ the estimated probability of $Y=1$.

## Fit Logit Regression With Predictor(s)

Let's add a predictor to the logit regression model. Say we want to use `ukrspeakhome` to explain the dependent variable.

With the predictor included, the log odds of a respondent supporting secession abortion is $$\log\left(\frac{p}{1-p}\right)=\alpha + \beta(\text{ukrspeakhome}).$$ Let's run the analysis.

```{r, echo=T, eval=T}
mod_speak <- glm(secede ~ ukrspeakhome, data = dta_sel, family = binomial)
summary(mod_speak)
``` 

The estimated coefficient for `ukrspeakhome` is -1.3664 and statistically significant. How do we interpret the results?

Unlike the model with no predictor, taking the exponent of the coefficient will give us the **odds ratio** (OR). OR is notoriously confusing, but here is the basic intuition with minimum math involved. 

First, recall that we define the model as $$\log\left(\frac{p}{1-p}\right)=\alpha+\beta(\text{ukrspeakhome})+\epsilon,$$ where the outcome variable is the log odds of Ukrainian citizens in favor of secession.

Next, $\beta$ tells us how the *log odds* of people supporting secession will change when we increase the predictor from 0 to 1. Since our predictor `ukrspeakhome` is a binary variable, we are basically comparing respondents who speak Ukrainian at home ($X=1$) to those who do not speak Ukrainian at home ($X=0$): $$\beta=\log(\text{Odds when X}=1)-\log(\text{Odds when X}=0),$$ where by "Odds" we mean **the odds of respondents supporting secession.**

By the **quotient law of logarithms**, the **the difference between two logs** (the left hand side below) can be rewritten as **the log of them dividing up each other** (the right hand side below):

\begin{equation}
\begin{split}
\beta=\log(\text{Odds when X}=1)-\log(\text{Odds when X}=0)=\log\left(\frac{\text{Odds when X}=1}{\text{Odds when X}=0}\right)
\end{split}
\end{equation}

In other words, the estimated slope $\widehat{\beta}$ is the log of our odds ratio with base $e$. Taking the exponent of $\widehat{\beta}$ will return odds ratio. In doing so, we have $$e^\beta=\frac{\text{Odds when X}=1}{\text{Odds when X}=0}.$$ This is **the odds ratio when people speak Ukranian at home.** 

Let's do this step by step. Taking the exponent of our $\widehat{\beta}$ will return a value below 1, suggesting the odds of supporting secession when $X=1$ is lower than the odds of supporting secession when $X=0$ (i.e., the denominator is larger than the numerator).

```{r, echo=T, eval=T}
beta <- coef(mod_speak)
exp(beta)
```

We can use `confint()` to get the confidence interval of the odds ratio of `ukrspeakhome` to see if it is stays below 1.

```{r, echo=T, eval=T, message=F}
coefs_ci <- confint(mod_speak) # CIs of estimated beta
coefs_ci
exp(coefs_ci) # CIs of odds ratio
```

In a nutshell, odds-ratio (OR) is **a ratio of two different odds** when we change the predictor `ukrspeakhome` by one unit. And OR can only be one of the three conditions below, each of which has a different substantive implication.

Since we find $OR_{ukrspeakhome}<1$ even after we consider its confidence interval, **people speaking Ukrainian at home are less likely to support secession.** 

```{r echo=FALSE, out.width="90%", fig.align="center"}
knitr::include_graphics("or_crop.pdf")
```

### Summary

Again, we can sum up the process as follows when we include predictor(s) in the logit regression model:

  - $\beta=\log\left(\frac{\text{Odds when X}=1}{\text{Odds when X}=0}\right);$ the estimated slope is the estimated **log of odds ratio**,

  - $e^\beta=\frac{\text{Odds when X}=1}{\text{Odds when X}=0}$ the exponent of the estimated slope is the estimated **odds ratio**

  - You can still uncover $p$ when you include predictors, and $p=\frac{e^{\alpha+\beta X}}{1+e^{\alpha+\beta X}}$.

## Practical Guide for Logit Regression

When you conduct a logit regression (with predictors), do the following:

  - Step 1: Write down a table like the one above to think through different scenarios.
  
  - Step 2: Run the logit regression (use `glm()`); see if your predictor(s) have any statistically significant coefficients.
  
  - Step 3: Take the exponent of your coefficients (use `exp()`); this will be the odds ratio when we change the corresponding predictor by one unit. 

  - Step 4: Explain the odds-ratio (OR) using the table you made.
    - If $OR=1$, the predictor is not associated with the (odds of the) outcome (this scenario is going to be rare in practice).
    - If $OR>1$, the predictor is positively associated with the (odds of the) outcome.
    - If $OR<1$, the predictor is negatively associated with the (odds of the) outcome.
    
  - Step 5: Obtain the confidence interval of the odds ratio to make sure it stays in one of the three situations.

# Questions

## Question 1 {.unnumbered}

Use `?glm` to see more information about `glm()`. What does the argument `family` do? What is the default for `family`? 

## Question 2 {.unnumbered}

Replace `ukrspeakhome` with `Russiathreat` in the bivariate logit regression. Answer the following questions.

  - Interpret the estimated odds ratio of `Russiathreat` with 95\% confidence intervals.
  
  - Compare the estimated odds ratio of `ukrspeakhome` and `Russiathreat`. Discuss your observations -- can you say which one predictor has a larger influnece over the outcome variable than the other?
  
  - Read through the codebook provided by Beesley and Cooper and find one variable and add it to the specified model. Present the table with `stargazer()` function and discuss your observations.

\newpage

# Extra: Derive Predicted Probability from Logit Regression

Instead of using odds ratio, the most intuitive way to use the **`predict()`** function.

We can plug the model we have just estimated into `predict()` to compute the predicted **log-odds** for each observation. Including `type="response"` will return the predicted **probabilities**. 

```{r, echo=T, eval=T, message=F}
fit_log_odds <- predict(mod_speak) # for predicted log odds
fit_prob <- predict(mod_speak, type="response") # for predicted probabilities
```  

We can use the **`predict()`** function to estimate how the probability of respondents supporting secession will change depending on their language use at home.

First, let's use `data.frame()` to create a new dataframe to include the unique values of `ukrspeakhome`.

```{r, echo=T, eval=T, message=F}
data_predict <- data.frame(ukrspeakhome = c(0,1))
data_predict
```

Now let's obtain the predicted log-odds, odds, and probabilities when we vary the value of `ukrspeakhome`.

```{r, echo=T, eval=T, message=F}
fit_prob <- predict(mod_speak, newdata=data_predict, type="response")
fit_log_odds <- predict(mod_speak, newdata=data_predict)
fit_mod_s <- data.frame(ukrspeakhome = c(0,1),
                        fit_prob = as.matrix(fit_prob),
                        fit_log_odds = as.matrix(fit_log_odds))
fit_mod_s$fit_odds <- exp(fit_mod_s$fit_log_odds)
fit_mod_s
```

We can see that the predicted probabilities of supporting secession for `ukrspeakhome`$=0$ and $=1$ are 0.22 and 0.07, respectively. Again, respondents who speak Ukrainian at home are **less** likely to support the secession of Donbas.

# Extra: Multiple Logit Regression

```{r, echo=T, eval=T, message=F}
dta_sel <- dta |>
  dplyr::select(secede, above3Khryv, age, female, ukrspeakhome, Russiathreat) |>
  drop_na() # remove the NAs for model comparison
```

## Fit the Model

```{r, echo=T, eval=T, message=F}
mod1 <- glm(secede ~ ukrspeakhome + age + female,
            data = dta_sel, family = binomial)
mod2 <- glm(secede ~ Russiathreat + age + female,
            data = dta_sel, family = binomial)
mod3 <- glm(secede ~ ukrspeakhome + Russiathreat + age + female,
            data = dta_sel, family = binomial)
```

## Regression Table

```{r, echo=T, eval=T, message=F}
library(stargazer)
stargazer(list(mod1, mod2, mod3),
          omit.stat = c("f", "rsq", "ser"),
          covariate.labels = c("Speak Ukranian at Home (=1)",
                               "Russia is a Threat",
                               "Age",
                               "Female (=1)"),
          type = "text",
          digits = 3, 
          no.space = T,
          intercept.bottom = TRUE,
          star.cutoffs = c(0.05, 0.01, 0.001))
```

## Model Comparison

```{r, echo=T, eval=T, message=F}
anova(mod1, mod2, mod3, test="Chi")
```

## Sum of Squared Residuals

```{r, echo=T, eval=T, message=F}
sum(residuals(mod1)^2)
sum(residuals(mod2)^2)
sum(residuals(mod3)^2)
```

## Marginal Predicted Probability

We can obtain the predicted probabilities of different language uses at home using the same function `predict()`. We will again recreate a new dataframe to record the unique values of `ukrspeakhome`. 

As we will be using a multiple logit model `mod3` to carry out the simulation/prediction exercise, we will have to set other variables in the model at its mean.

```{r, echo=T, eval=T, message=F}
data_predict <- data.frame(ukrspeakhome = c(0,1),
                           Russiathreat = mean(dta_sel$Russiathreat, na.rm=T),
                           age = mean(dta_sel$age, na.rm=T),
                           female = mean(dta_sel$female, na.rm=T))
data_predict

fit_prob <- predict(mod3, newdata=data_predict, type="response")
fit_log_odds <- predict(mod3, newdata=data_predict)
fit_mod_s <- data.frame(ukrspeakhome = c(0,1),
                        fit_prob = as.matrix(fit_prob),
                        fit_log_odds = as.matrix(fit_log_odds))
fit_mod_s$fit_odds <- exp(fit_mod_s$fit_log_odds)
fit_mod_s
```

# Extra: Including Weights in the Analysis

The `survey` and `srvyr` packages makes it easy to account for survey weights in our analysis.

The function `svyglm()` is similar to the conventional `glm()` function except that `svyglm()` use `design` (i.e., the survey object) instead of `data`.

Type `?svyglm` for more information about the function. Alternatively, you can visit the `survey` package's vignette page. The section **Regression models** provides additional information.

In this section, we will use the updated data frame `dta_sel`, which should have included all the variables we have added so far, to carry out the following activities.

  - Use `as_survey` from `srvyr` to create a survey design object. 
  
  - Use `svyglm()` from `survey` to fit logit regression.

In general, including the weights should not impact the results much unless the sample is very biased in relation to the (pre-specified) population.

```{r, echo=T, eval=T}
dta_sel <- dta |>
  dplyr::select(secede,
                above3Khryv, age, female, ukrspeakhome, Russiathreat,
                oblastname, weight) |> # add survey design vars
  mutate(id = 1:nrow(dta)) |> # create a unique ID for each respondent
  drop_na()
```

## Create Survey Design Object

Note that the original dataset does not include much information about the sampling scheme, so it is not clear how the respondents are sampled. 

Below we assume the Pew Research Center created the study population (i.e., the sample) with stratification by oblast (use the `oblastname` variable). Since there is no information about the population size of each oblast, we will ignore it.

```{r, echo=T, eval=T}
dta_sel_survey <- dta_sel %>%
  srvyr::as_survey(ids = id,
            strata = oblastname,
            #fpc = population,
            weights = weight)
dta_sel_survey
```

## Fit Logit Regression

To carry out logit regression with weights included, we need to use `svyglm()` in the `survey` package. 

```{r, echo=T, eval=T, message=F}
mod_s_speak <- survey::svyglm(secede ~ ukrspeakhome,
                              design = dta_sel_survey, # the survey design object
                              family = binomial)
summary(mod_s_speak)
```

Let's take a look at the odds-ratio by taking the exponent of the `ukrspeakhome` coefficient.

```{r, echo=T, eval=T, message=F}
exp(coef(mod_s_speak))
```