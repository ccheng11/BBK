---
title: |
  |
  |
  | Causal Inference in Social Research
  |
  |
author: |
  | Advanced Topics in Quant Social Research
  |
output:
  beamer_presentation:
    includes:
      in_header: mystyle.tex
  slidy_presentation: default
  ioslides_presentation: default
fontsize: 10pt
---

# Plan of today

\begin{itemize}
  \item Why causal inference
  \vspace{0.5cm}
  \item Identification strategies: Experimental vs observational studies
  \vspace{0.5cm}
  \item Frontiers of causal inference: Bias, sensitivity, mediation, and many more
  \vspace{0.5cm}
  \item Concluding remarks: Welcome to the club
\end{itemize}

# Motivation: Why causality matters?

\begin{itemize}
  \item Causal inference is \textbf{useful} -- social researchers and policy analysts frequently address simple and yet important cause-and-effect questions
  \vspace{0.5cm}
  \item Causal inference is \textbf{crucial} -- ignorance of the distinction between correlation and causality can be a matter of life and death
  \vspace{0.5cm}
  \item Causal inference is \textbf{difficult} -- the complexity of real world makes it very difficult to tease out causality
\end{itemize}

# Examples of cause-and-effect questions in political science

\begin{itemize}
  \item \textbf{Democratic politics}. Does incumbency status affect election outcomes (Lee 2008)? Do fair and clean elections lead to government responsiveness (Ofosu 2019)?
  \vspace{0.4cm}
  \item \textbf{Legacy of historical events}. Does historical black slavery have an lasting impact on white people's attitudes toward the African American people (Acharya et al 2018)?
  \vspace{0.4cm}
  \item \textbf{Political economy of development}. Does top-down monitoring reduce local corruption (Olken 2007)? Does the election of criminal politicians undermine local economic development (Cheng ahd Urperlainen 2019)? Does descriptive representation of marginalized social groups reduce inequality? Does immigration undermine economic growth (Hainmueller et al 2019)?
  \vspace{0.4cm}
  \item \textbf{Global governance}. Does international peacekeeping effort reduce conflicts? Does foreign aid work?
\end{itemize}

# Causality is complex (and yet intuitive)

\vspace{0.2cm}
```{r echo=FALSE, out.width="40%", fig.align="center"}
knitr::include_graphics("Figs/xy.pdf")
```
\vspace{0.6cm}
\begin{itemize}
  \item Existence: Does \textbf{X} really cause \textbf{Y}?
  \item Importance: If yes, to how much degree does \textbf{X} matter?
  \item Mechanism: How and why does \textbf{X} affect \textbf{Y}?
  \begin{itemize}
    \item Heterogeneous effect
    \item Mediation analysis
    \item Process tracing and qualitative comparative analysis
  \end{itemize}
\end{itemize}

# Causal inference is hard (thanks to real world)

\begin{itemize}
  \item Lack/absence of valid \textbf{counterfactuals} -- "fundamental problem of causal inference" (Holland 1986)
  \vspace{1cm}
  \item \textbf{Selection into the treatment} (Dunning 2012) -- correlation is not the same as causation
\end{itemize}

# Absence of valid counterfactuals

\begin{itemize}
  \item The inference of preference causality requires "counterfactuals" at individual level
  \vspace{1cm}
  \item Data cannot tell us when this situation holds, because we only get to observe one of the "potential outcomes" for each observation or participant
  \vspace{1cm}
  \item \textbf{Solution}: Use group-level \textbf{average} difference under treatment and control states to infer causality
\end{itemize}

# Modeling counterfactuals with potential outcome framework

\vspace{0.4cm}
With a binary treatment $D_i=\{0,1\}$, 
\begin{equation}
  \begin{split}
  Y_i & =
  \begin{cases}
  Y_{1i} \quad \text{if} \quad D_i=1\\
  Y_{0i} \quad \text{if} \quad D_i=0
  \end{cases}\\
  & = D_iY_{1i} + (1-D_i)Y_{0i},
  \end{split}
\end{equation}
where $Y_i$ is the observed outcome of interest for observation or respondent $i$ such that
\begin{itemize}
  \item $Y_{1i}$ is the potential outcome when $i$ receives the treatment ($D_i=1$)
  \item $Y_{0i}$ is the potential outcome when $i$ does not receive the treatment ($D_i=0$)
\end{itemize}

---

```{r echo=FALSE, out.width="50%", fig.align="center"}
knitr::include_graphics("Figs/eeao.pdf")
```

# Selection process into treatment is complicated

```{r echo=FALSE, out.width="60%", fig.align="center"}
knitr::include_graphics("Figs/assn.pdf")
```
\vspace{0.5cm}
\begin{itemize}
  \item Almost always, treatment assignment (?) is determined by some data generation process (DGP)
  \item Usually in real life, however, the exact assignment mechanism is not clear and cannot be modeled perfectly
  \item In addition to causation, common causes of treatment and outcome (\textbf{confounders}) will also lead to correlation
\end{itemize}

# Example of selection bias: Police deployment and neighborhood crime rate

```{r echo=FALSE, out.width="90%", fig.align="center"}
knitr::include_graphics("Figs/b2.pdf")
```
\vspace{0.3cm}
\begin{itemize}
  \item On average, neighborhoods that have more police officers also see more residents killed by gun violence
  \item Is the police department incompetent (or corrupt])? Or even worse, are the police officers involved in some covert collusion with the local crime syndicate?
\end{itemize}

# Example of selection bias: Intl peacekeeping and conflict resolution/prevention

```{r echo=FALSE, out.width="90%", fig.align="center"}
knitr::include_graphics("Figs/b3.pdf")
```
\vspace{0.3cm}
\begin{itemize}
  \item On average, no statistically significant results exist to show that UN peacekeeping troops reduce the likelihood of communal violence
  \item Is sending UN peacekeeping troops a waste of time and money?
\end{itemize}

# Example of selection bias: Hospital treatment and patient survival

```{r echo=FALSE, out.width="90%", fig.align="center"}
knitr::include_graphics("Figs/b1.pdf")
```
\vspace{0.3cm}
\begin{itemize}
  \item On average, people who visit hospitals frequently have a higher death rate.
  \item Are hospitals some sort of "killing" machines?
\end{itemize}

# Randomization comes to rescue

With randomization, we break the link between $X$ and $C$ (or $U$, unobserved confounders). 
```{r echo=FALSE, out.width="50%", fig.align="center"}
knitr::include_graphics("Figs/cxy2.pdf")
```
\vspace{0.2cm}
It follows that,
\begin{equation}
E(Y_{X=1})-E(Y_{X=0}) = \underbrace{E(Y|X=1)}_{\text{observed treated units}} - \underbrace{E(Y|X=0)}_{\text{observed control units}}.
\end{equation}
... and happily, thereafter.

# Causal inference as a field

\begin{itemize}
  \item We need to know when the data allow us to "identify" a causal effect
  \vspace{0.1cm}
  \begin{itemize}
    \item Obtain valid counterfactuals (i.e., comparable treated and control observations)
    \item Remove the selection bias (i.e., exogenous variation in the treatment status)
  \end{itemize}
  \vspace{0.2cm}
  \item Causal identification without an experiment requires "assumptions" best made reasonable by carefully thought-out research designs
  \vspace{0.1cm}
  \begin{itemize}
    \item If an effect is not identified, no estimation method will recover it
    \item Estimation strategies (e.g., t-test, regression, matching, weighting, 2SLS, 3SLS, SEM, GMM, GEE, dynamic panel, etc.) are secondary to the identification assumptions
  \end{itemize}
\end{itemize}

# Experiment vs. observational studies

\begin{itemize}
  \item Randomized experiment: well-defined treatment, clear distinction between covariates and outcomes, control of assignment mechanism.
  \begin{figure}
    \centering
    \includegraphics[scale=0.25]{Figs/end3}
  \end{figure}
  \begin{center}
    "That's a whoopsie!"
  \end{center}
\end{itemize}

# Experiment vs. observational studies (Dunning 2012)

\begin{itemize}
  \item Randomized experiment: well-defined treatment, clear distinction between covariates and outcomes, control of assignment mechanism.
  \vspace{0.2cm}
  \item Good observational study: Well-defined treatment, clear distinction between covariates and outcomes, (nearly) precise knowledge of assignment mechanism.
  \vspace{0.2cm}
  \item Poor observational study: Hard to say when treatment began or what the treatment really is; distinction between covariates and outcomes is blurred; no precise knowledge of assignment mechanism.
\end{itemize}
\vspace{0.3cm}
\textbf{The bottom line}: Causal inference requires that treated and control units in the study population are comparable such that the only difference is (as if) the treatment status.

# ID strategies for observational studies: An overview

\begin{itemize}
  \item Selection on the observables (SOO)
  \vspace{0.4cm}
  \item Instrumental variables (IV)
  \vspace{0.4cm}
  \item Regression discontinuity design (RDD)
  \vspace{0.4cm}
  \item Difference-in-difference (DiD)
  \vspace{0.4cm}
  \item ... and many more (e.g., event study and synthetic control)
\end{itemize}

# Practical reminders

\begin{itemize}
  \item State the "causal" question of interest: Policy-relevant and/or theoretically important
  \item Know the assumptions you need to support the causal claim of interest
  \item Design your research to maximize the credibility of causal claims -- know where your study falls on the credibility spectrum
  \item Master the tools for testing to maximize the credibility of causal claims
  \item Be aware of the priority: Existence, magnitude, and/or mechanisms?
\end{itemize}
\vspace{0.3cm}
The goal is NOT to tell you that you cannot study certain topics (we are not causality police); rather, we seek to let you answer the questions of interest in the best way possible.

# Appendix: Modeling selection bias (directed acyclic graphs or DAG)

```{r echo=FALSE, out.width="50%", fig.align="center"}
knitr::include_graphics("Figs/cxy.pdf")
```
\vspace{0.2cm}
The average effect of binary $D$ on $Y$ with the presence of observed $C$ (discrete confounders) is then
\begin{equation}
\begin{split}
& E(Y_{D=1})-E(Y_{D=0}) = \\\vspace{0.1cm}
  & \quad \sum_C \underbrace{E(Y|X=1,C=c)P(C=c)}_{\text{observed treated units with stratum $c$}} - \sum_C \underbrace{E(Y|X=0,C=c)P(C=c)}_{\text{observed control units with stratum $c$}}.
\end{split}
\end{equation}
\pause What if $C$ is unknown (i.e., $U$)?

# Appendix: Modeling selection bias

Using $i$ to denote individual units in the study sample with a binary treatment $D$,
\begin{equation}
\begin{split}
\underbrace{E[Y_i|D_i=1]-E[Y_i|D_i=0]}_{\text{Observed differences b/w treated and control}}
  & = \underbrace{E[Y_{1i}|D_i=1] - E[Y_{0i}|D_i=1]}_{\text{Avg treatment effect on the treated}} \\ 
  & \qquad + \underbrace{E[Y_{0i}|D_i=1] - E[Y_{0i}|D_i=0]}_{\text{Selection bias}},
\end{split}
\end{equation}
where
\begin{equation}
E[Y_{1i}|D_i=1] - E[Y_{0i}|D_i=1] = E[Y_{1i}-Y_{0i}|D_i=1].
\end{equation}
\pause
Can we get rid of selection bias?

# Randomization comes to rescue

With randomization, the treatment ($D_i$) and potential outcomes ($Y_i$) become independent of each other. As such,
\begin{equation}
\begin{split}
\underbrace{E[Y_i|D_i=1]-E[Y_i|D_i=0]}_{\text{Observed differences b/w treated and control}}
  & = \underbrace{E[Y_{1i}|D_i=1] - E[Y_{0i}|D_i=1]}_{\text{Avg treatment effect on the treated}} \\ 
  & \qquad + \underbrace{E[Y_{0i}|D_i=1] - E[Y_{0i}|D_i=0]}_{\text{Selection bias}} \\
  & = E[Y_{1i}-Y_{0i}|D_i=1] + E[Y_{0i}] - E[Y_{0i}] \\
  & = E[Y_{1i}-Y_{0i}].
\end{split}
\end{equation}
Hip hip hooray!
