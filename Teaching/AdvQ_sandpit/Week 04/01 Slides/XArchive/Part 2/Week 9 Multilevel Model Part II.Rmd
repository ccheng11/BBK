---
title: IQSR Multilevel/Hierarchical Modeling (Part II)
author:
  - Chao-Yo Cheng
output:
  beamer_presentation:
    includes:
      in_header: mystyle.tex
  slidy_presentation: default
fontsize: 10pt
---

## Plan ahead

\begin{itemize}
  \item Week 3: Thinking about your project
  \vspace{0.2cm}
  \item Weeks 4 and 5: Analyzing survey data
  \vspace{0.2cm}
  \item Weeks 8 and 9: Multilevel and hierarchical modeling
  \begin{small}
  \begin{itemize}
    \item Week 8: The fundamentals
    \item \textbf{Week 9: Assumptions and diagnostics}
  \end{itemize}
  \end{small}
  \vspace{0.2cm}
  \item Week 10: Concluding remarks, Q\&A, and post-term activities (TBD)
\end{itemize}

## Outline

\begin{itemize}
  \item Recap: Why multilevel modeling may be a good idea
  \item Multilevel and multivariate regression
  \item Theoretical motivation of multilevel modeling
  \item Examples of multilevel modeling
  \item Concluding remarks: Moving forward
\end{itemize}

## Recap: Multilevel/hierarchical modeling

\begin{itemize}
  \item Linear multilevel regression is an extension of (classical) linear regression (OLS).
  \item Linear multilevel regression can be used to analyze \textbf{nested data} (see below) by allowing observations in each cluster or group to have a unique fitted line (i.e., varying intercepts and/or slopes).
  \item Pros and cons
  \begin{itemize}
    \item Pros: Versatile, flexible and nuanced.
    \item Cons: Formal and computational tractability (complicated and time-consuming); hypothesis testing can be challenging (so go \textbf{Bayesian} please).
  \end{itemize}
\end{itemize}
```{r echo=FALSE, out.width="70%", fig.align="center"}
knitr::include_graphics("Figs/example.pdf")
```

## Example: Years of experiences and salaries across 5 depts

```{r echo=FALSE, out.width="101%", fig.align="center"}
knitr::include_graphics("Figs/lmm.pdf")
```

## Multivariate v multilvel linear regression

We want to use regression to explain $\text{var}(Y)$; the model's explanatory power can be improved by
\vspace{0.3cm}

\begin{itemize}
  \item Bivariate v multivariate: increasing the number of predictors (dimensions).
  \item Classical (single-) v multi-level: increasing the number of levels (hierarchies).
\end{itemize}

\vspace{0.3cm}
|                                    | Classical     | Multi-level  |
|------------------------------------|---------------|--------------|
| Bivariate (one predictor)          | `lm()`        | `lmer()`     |
| Multivariate (more than predictor) | `lm()`        | `lmer()`     |

## Classicial regression (fixed intercept and slopes)

\begin{itemize}
  \item Bivariate (one predictor): $Y=\alpha+\beta X+\epsilon$.
  \item Multivariate (two predictors): $Y=\alpha+\beta_1 X_1++\beta_2 X_2+\epsilon$.
\end{itemize}
\vspace{0.5cm}
```{r echo=F, eval=T, out.width="90%", fig.align="center", fig.height=5, fig.width=10, message=F}
par(mfrow=c(1,2))

attach(mtcars)
plot(wt, mpg, main="Regression\nlm(y~x)", xlab="X", ylab="Y", pch=19)
abline(lm(mpg ~ wt), col="red", lwd=2)

#scatterplot3d(wt, disp, mpg, main="Regression With Two Predictors", xlab="X1", ylab="X2", zlab="Y", pch=19)
#abline(lm(mpg ~ wt + disp), col="red", lwd=2)

library(scatterplot3d)
attach(mtcars)
s3d <- scatterplot3d(wt, disp, mpg, main="Regression\nlm(y~x1+x2)", xlab="X1", ylab="X2", zlab="Y", pch=19)
fit <- lm(mpg ~ wt + disp)
s3d$plane3d(fit)
```

## Multilevel regression (varying intercept and/or slopes)

\begin{itemize}
  \item Bivariate (one predictor; $Y=\alpha+\beta X+\epsilon$): there will be 3 multilevel models if one would like to varying $\alpha$ and/or $\beta$ across groups.
  \begin{itemize}
    \item Varying $\alpha$: $Y=\alpha_j+\beta X+\epsilon$.
    \item Varying $\beta$: $Y=\alpha+\beta_j X+\epsilon$.
    \item Varying $\alpha$ and $\beta$: $Y=\alpha_j+\beta_j X+\epsilon$.
  \end{itemize}
  \vspace{0.3cm}
  \item Multivariate (two predictors; $Y=\alpha+\beta_1 X_1++\beta_2 X_2+\epsilon$): there will be 7 multilevel models if one would like to varying $\alpha$, $\beta_1$, and/or $\beta_2$ across groups.
  \vspace{0.3cm}
  \pause
  \item For any baseline linear regression (fixed intercepts and slopes), there will be $2^k-1$ multilevel models one can fit (where $k$ refers to the number of predictors).
\end{itemize}

## Why linear "multilevel" regression

\begin{itemize}
  \item Practical motivation.
  \begin{itemize}
    \item When observations can be nested into different groups (or clusters).
    \item The statistical relationship between $Y$ and predictors ($X$s) can be different across different groups.
  \end{itemize}
  \vspace{0.4cm}
  \item Theoretical motivation.
  \begin{itemize}
    \item When observations can be nested into different groups (or clusters).
    \item Using linear regression to fit nested data can generate errors that violate the assumptions for OLS to be BLUE.
  \end{itemize}
\end{itemize}

## Assumptions for linear regression to be BLUE

\begin{itemize}
  \item Linearity and addivity: $Y$ is a linear function of the predictor(s).
  \item Normality, homoscedasticity, and independence of $\epsilon$.
  \begin{itemize}
    \item The residuals should be normally distributed; that is, probabilistically the model not produce extreme errors.
    \item The residuals should have equal variance; that is, errors should not be predictable; if violated, $\widehat{\beta}$ can be biased.
    \item The residuals should have equal variance; that is, the errors should not depend on each other.
  \end{itemize}
\end{itemize}

|                                    | Diagnostics                                          |
|------------------------------------|------------------------------------------------------|
| PG Certificate                     | V                                                    |
| Normality $\epsilon$               | Quantile-quantile plot                               |
| Homoscedasticity of $\epsilon$     | Residual plots ($\widehat{Y}$ or $X$ vs $\epsilon$)  |
| Independence of $\epsilon$         | Ad hoc statistics (e.g., Durbin–Watson)              |

## Assumptions for linear regression to be BLUE

\begin{itemize}
  \item In real life, nested data is quite common.
  \vspace{0.3cm}
  \item Using linear regression to analysis nested data can be problematic, because the error of an observation may be determined by the group to which it belongs to (hence no \textbf{homoscedasticity} and/or \textbf{independence}).
  \vspace{0.3cm}
  \item Linear multilevel regression allows us to use linear functions to model nested data. 
\end{itemize}

## Example: Gelman et al (2008)

\begin{itemize}
  \item "How is income related to individual's vote choice?"
  \item Results from multilevel regression show that \textbf{income matters more in red (i.e., Republican) America}.
\end{itemize}
\vspace{0.2cm}
```{r echo=FALSE, out.width="70%", fig.align="center"}
knitr::include_graphics("Figs/qjps.pdf")
```

## Example: Blaydes and Linzer (2012)

\begin{itemize}
  \item "How is religiosity related to anti-Americanism among Muslims?"
  \item Religiosity is positively correlated with sentiment against the US when \textbf{a country is polarized over religious–secular issue dimension}.
\end{itemize}
\vspace{0.2cm}
```{r echo=FALSE, out.width="100%", fig.align="center"}
knitr::include_graphics("Figs/apsr.pdf")
```

## Extra: Advanced multilevel modeling

\begin{itemize}
  \item What if we want to include group-level predictors (Gelman and Hill 2007)? 
  \item What if there are clusters across levels -- should we include all of them (Finch et al 2014)? For instance,
  \begin{itemize}
    \item In administrative data, \textbf{towns} can be nested into \textbf{municipalities}, which can then be nested into \textbf{provinces}.
    \item In a cross-national survey, \textbf{respondents} can be nested into \textbf{countries}, which can then be bested into \textbf{continents}.
  \end{itemize}
  \vspace{0.2cm}
  \item What if the observations can be nested into groups and time (Fairbrother 2013)?
  \vspace{0.2cm}
  \item What if we want to include group-level predictors? -- group-level estimates can be problematic when we do not have too many groups (Bryan et al 2016).
\end{itemize}

## Extra: Advanced multilevel modeling

\begin{itemize}
  \item What if we want to include group-level predictors (Gelman and Hill 2007)? 
  \item What if there are clusters across levels -- should we include all of them (Finch et al 2014)? 
  \vspace{0.2cm}
  \item What if the observations can be nested into groups and time (Fairbrother 2013)?
  \begin{itemize}
    \item In longitudinal cross-national survey, you may have \textbf{repeated measures of each respondent} (e.g., education and income) across different \textbf{countries} over the \textbf{years}.
    \item In longitudinal school data, you may have \textbf{repeated measures of each student} (e.g., race and exam mark) across different \textbf{schools} over the \textbf{semesters}.
  \end{itemize}
  \vspace{0.2cm}
  \item What if we want to include group-level predictors? -- the estimates at the group level can be problematic when we do not have too many groups (Bryan et al 2016).
\end{itemize}

## Tutorial: Education and happiness across different political regimes

\begin{itemize}
  \item We will use \textbf{World Values Survey} (Wave 7) to study how \textbf{education} is related to \textbf{happiness}.
  \vspace{0.2cm}
  \item We will cluster the respondents by the \textbf{type of political regimes} (e.g., autocracy, anocracy, and democracy).
  \vspace{0.2cm}
  \item The question is: \textbf{How does the correlation between \texttt{education} and \texttt{happiness} vary by political regime}?
  \vspace{0.2cm}
  \item Highlights of class discussion: Modeling strategy and assumptions.
\end{itemize}

---

```{r echo=FALSE, out.width="100%", fig.align="center"}
knitr::include_graphics("Figs/review.pdf")
```
\vspace{0.4cm}
\begin{center}
\url{https://doi.org/10.1146/annurev-psych-020821-103525}
\end{center}
